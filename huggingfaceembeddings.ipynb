{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import PyPDF2\n",
    "import pandas as pd\n",
    "# from transformers import AutoTokenizer, \n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read pdf into dataframe, normalize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages in PDF:  41\n",
      "Finished processing page 1\n",
      "Finished processing page 2\n",
      "Finished processing page 3\n",
      "Finished processing page 4\n",
      "Finished processing page 5\n",
      "Finished processing page 6\n",
      "Finished processing page 7\n",
      "Finished processing page 8\n",
      "Finished processing page 9\n",
      "Finished processing page 10\n",
      "Finished processing page 11\n",
      "Finished processing page 12\n",
      "Finished processing page 13\n",
      "Finished processing page 14\n",
      "Finished processing page 15\n",
      "Finished processing page 16\n",
      "Finished processing page 17\n",
      "Finished processing page 18\n",
      "Finished processing page 19\n",
      "Finished processing page 20\n",
      "Finished processing page 21\n",
      "Finished processing page 22\n",
      "Finished processing page 23\n",
      "Finished processing page 24\n",
      "Finished processing page 25\n",
      "Finished processing page 26\n",
      "Finished processing page 27\n",
      "Finished processing page 28\n",
      "Finished processing page 29\n",
      "Finished processing page 30\n",
      "Finished processing page 31\n",
      "Finished processing page 32\n",
      "Finished processing page 33\n",
      "Finished processing page 34\n",
      "Finished processing page 35\n",
      "Finished processing page 36\n",
      "Finished processing page 37\n",
      "Finished processing page 38\n",
      "Finished processing page 39\n",
      "Finished processing page 40\n",
      "Finished processing page 41\n",
      "Finished processing all pages.\n",
      "-------------------------------------------------------------------------------------------------------- \n",
      " PDF to DataFrame complete. \n",
      " Here is the first 5 rows of the dataframe:    page                                               text\n",
      "0    1   \\n© 201 6 Microsoft   \\n \\nSurface Book  \\nUs...\n",
      "1    2    \\n© 201 6 Microsoft   Page ii \\n \\n \\n \\n \\n...\n",
      "2    3    \\n© 201 6 Microsoft   Page iii \\nContents  \\...\n",
      "3    4    \\n© 201 6 Microsoft   Page iv \\nBROWSING TIP...\n",
      "4    5    \\n© 201 6 Microsoft   Page v \\nAudio problem... \n",
      " --------------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------------------------------- \n",
      " [text] column has been normalized. \n",
      " Here is the first 5 rows of the dataframe:    page                                               text\n",
      "2    3  © 201 6 Microsoft Page iii Contents Meet Surfa...\n",
      "3    4  © 201 6 Microsoft Page iv BROWSING TIPS .........\n",
      "4    5  © 201 6 Microsoft Page v Audio problems .........\n",
      "5    6  © 201 6 Microsoft Page 1 Meet Surface Book Get...\n",
      "6    7  © 201 6 Microsoft Page 2 The 10 -point multi -... \n",
      " --------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def read_pdf_into_df(pdf_file_path):\n",
    "    # create a pdf file object\n",
    "    pdfFileObj = open(pdf_file_path, 'rb') # rb means read binary mode \n",
    "    # create a pdf reader object\n",
    "    pdfReader = PyPDF2.PdfReader(pdfFileObj) \n",
    "    # print the number of pages in pdf document \n",
    "    print('Number of pages in PDF: ', len(pdfReader.pages)) \n",
    "\n",
    "    # declare an empty dataframe with two columns: Page and Text (for page number and text of each page)  \n",
    "    df = pd.DataFrame(columns=['page', 'text'])\n",
    "\n",
    "    # loop through the number of pages in the document, get each page's text, write to a new row in dataframe  \n",
    "    for i in range(0, len(pdfReader.pages)):      # for each page \n",
    "\n",
    "        pageObj = pdfReader.pages[i]     # get that page object from the pdf reader object using indexing  \n",
    "\n",
    "        text = pageObj.extract_text()       # extract the text from that page object  \n",
    "\n",
    "        df_temp = pd.DataFrame([[i+1,text]], columns=['page', 'text'])     # create temporary dataframe to hold information for each iteration (page number and text on that page)  \n",
    "\n",
    "        # df = df.append(df_temp)            # append temporary dataframe to master dataframe at end of each iteration (loop through all pages of document)  \n",
    "        df = pd.concat([df, df_temp], ignore_index=True)     # append temporary dataframe to master dataframe at end of each iteration (loop through all pages of document)\n",
    "\n",
    "        print('Finished processing page %d' % (i+1))      # print statement so you can see what pages have been processed already while script is running \n",
    "\n",
    "    print('Finished processing all pages.')               # print statement when script has finished running \n",
    "\n",
    "    return df\n",
    "\n",
    "surface_user_guide_path = 'C:/Users/ianadams/OneDrive - Microsoft/surface-book-user-guide-EN.pdf'\n",
    "pdf_df = read_pdf_into_df(surface_user_guide_path)\n",
    "print('--------------------------------------------------------------------------------------------------------', '\\n',\\\n",
    "      'PDF to DataFrame complete.', '\\n', 'Here is the first 5 rows of the dataframe: ', pdf_df.head(5), '\\n',\\\n",
    "          '--------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "rows_to_drop = list(range(0,2)) # Drops Cover and Copyright\n",
    "# rows_to_drop = list(range(0,5)) # Drops Cover and Table of Contents\n",
    "pdf_df = pdf_df.drop(rows_to_drop, axis=0)\n",
    "\n",
    "# s is input text\n",
    "def normalize_text(s, sep_token = \" \\n \"):\n",
    "    s = re.sub(r'\\s+',  ' ', s).strip()\n",
    "    s = re.sub(r\". ,\",\"\",s)\n",
    "    # remove all instances of multiple spaces\n",
    "    s = s.replace(\"..\",\".\")\n",
    "    s = s.replace(\". .\",\".\")\n",
    "    s = s.replace(\"\\n\", \"\")\n",
    "    s = s.strip()\n",
    "    \n",
    "    return s\n",
    "\n",
    "pdf_df['text'] = pdf_df['text'].apply(lambda x : normalize_text(x))\n",
    "print('--------------------------------------------------------------------------------------------------------', '\\n',\\\n",
    "      '[text] column has been normalized.', '\\n', 'Here is the first 5 rows of the dataframe: ', pdf_df.head(5), '\\n',\\\n",
    "          '--------------------------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tokenizer and use pretrained RobertaForQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_length = 384  # The maximum length of a feature (question and context)\n",
    "# doc_stride = 128  # The allowed overlap between two part of the context when splitting is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pdf_df['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    [© 201 6 Microsoft Page iii Contents Meet Surf...\n",
      "3    [© 201 6 Microsoft Page iv BROWSING TIPS , , ,...\n",
      "4    [© 201 6 Microsoft Page v Audio problems , , ,...\n",
      "5    [© 201 6 Microsoft Page 1 Meet Surface Book Ge...\n",
      "6    [© 201 6 Microsoft Page 2 The 10 -point multi ...\n",
      "Name: test_column, dtype: object\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "def get_string(text):\n",
    "    return text.split('.')\n",
    "#Apply the function to the dataframe \n",
    "pdf_df['test_column'] = pdf_df['text'].apply(get_string).tolist()\n",
    "print(pdf_df['test_column'].head(5))\n",
    "print(type(pdf_df['test_column']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     © 201 6 Microsoft Page iii Contents Meet Surfa...\n",
       "3     © 201 6 Microsoft Page iv BROWSING TIPS .........\n",
       "4     © 201 6 Microsoft Page v Audio problems .........\n",
       "5     © 201 6 Microsoft Page 1 Meet Surface Book Get...\n",
       "6     © 201 6 Microsoft Page 2 The 10 -point multi -...\n",
       "7     © 201 6 Microsoft Page 3 Ports and connectors ...\n",
       "8     © 201 6 Microsoft Page 4 Apps Surface Book com...\n",
       "9     © 201 6 Microsoft Page 5 Set up Windows Press ...\n",
       "10    © 201 6 Microsoft Page 6 With the Clipboard de...\n",
       "11    © 201 6 Microsoft Page 7 Note: Surface Book us...\n",
       "12    © 201 6 Microsoft Page 8 Lock screen When you ...\n",
       "13    © 201 6 Microsoft Page 9 Off or shut down Go t...\n",
       "14    © 201 6 Microsoft Page 10 Increases keyboard b...\n",
       "15    © 201 6 Microsoft Page 11 Surface Pen (Surface...\n",
       "16    © 201 6 Microsoft Page 12 3. If you see your a...\n",
       "17    © 201 6 Microsoft Page 13 4. Follow the on -sc...\n",
       "18    © 201 6 Microsoft Page 14  In the lower -left...\n",
       "19    © 201 6 Microsoft Page 15 While you're in Task...\n",
       "20    © 201 6 Microsoft Page 16 For info on personal...\n",
       "21    © 201 6 Microsoft Page 17 Browsing tips  Sele...\n",
       "22    © 201 6 Microsoft Page 18 To save a file from ...\n",
       "23    © 201 6 Microsoft Page 19  Click the top butt...\n",
       "24    © 201 6 Microsoft Page 20 Save screenshots in ...\n",
       "25    © 201 6 Microsoft Page 21 Apps and the Windows...\n",
       "26    © 201 6 Microsoft Page 22 Microsoft Edge Micro...\n",
       "27    © 201 6 Microsoft Page 23 Weather The Weather ...\n",
       "28    © 201 6 Microsoft Page 24 Connect devices and ...\n",
       "29    © 201 6 Microsoft Page 25 Without external spe...\n",
       "30    © 201 6 Microsoft Page 26 DisplayPort or HDMI ...\n",
       "31    © 201 6 Microsoft Page 27 1. Select the search...\n",
       "32    © 201 6 Microsoft Page 28 Set the default audi...\n",
       "33    © 201 6 Microsoft Page 29 Record audio You can...\n",
       "34    © 201 6 Microsoft Page 30 To learn more about ...\n",
       "35    © 201 6 Microsoft Page 31 Change camera option...\n",
       "36    © 201 6 Microsoft Page 32  Photos app : Selec...\n",
       "37    © 201 6 Microsoft Page 33 You can enter the se...\n",
       "38    © 201 6 Microsoft Page 34 Ease of Access optio...\n",
       "39    © 201 6 Microsoft Page 35  Closed captions  ...\n",
       "40    © 201 6 Microsoft Page 36 For more info, see C...\n",
       "Name: text_string, dtype: string"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_df['text_string'] = pdf_df['text'].astype('string')\n",
    "pdf_df['text_string']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.0037429388612508774,\n",
       "  'start': 1600,\n",
       "  'end': 1619,\n",
       "  'answer': 'DisplayPort or HDMI'},\n",
       " {'score': 0.0001963590766536072,\n",
       "  'start': 1552,\n",
       "  'end': 1619,\n",
       "  'answer': 'external spe... 30 © 201 6 Microsoft Page 26 DisplayPort or HDMI'},\n",
       " {'score': 0.0001813643757486716,\n",
       "  'start': 1600,\n",
       "  'end': 1611,\n",
       "  'answer': 'DisplayPort'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This performs best thus far\n",
    "from transformers import RobertaTokenizer, RobertaForQuestionAnswering, pipeline\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"deepset/roberta-base-squad2\")\n",
    "model = RobertaForQuestionAnswering.from_pretrained(\"deepset/roberta-base-squad2\")\n",
    "\n",
    "question = 'what ports and connectors does my surface have?' \n",
    "\n",
    "# context = pdf_df['text'].to_string(index=True) # This does ok...but not great\n",
    "context = pdf_df['text_string'].to_string(index=True)\n",
    "\n",
    "oracle  = pipeline(model=model, tokenizer=tokenizer, framework='pt', task='question-answering', top_k=3,\\\n",
    "                    doc_stride=256, max_answer_len=45, max_seq_len=384, max_question_len=64, align_to_words=True)\n",
    "QA_input = {\n",
    "    'question': question,\n",
    "    'context': context,\n",
    "}\n",
    "\n",
    "res = oracle(QA_input)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering, pipeline\n",
    "# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "# model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# question = 'what ports and connectors does my surface have?' \n",
    "\n",
    "# context = pdf_df['text'].to_string(index=True)\n",
    "\n",
    "# oracle  = pipeline(task='question-answering', model=model, tokenizer=tokenizer, framework='pt', doc_stride=128, max_answer_len=45, max_seq_len=348)\n",
    "# QA_input = {\n",
    "#     'question': question,\n",
    "#     'context': context\n",
    "# }\n",
    "# res = oracle(QA_input)\n",
    "# res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Question and corpus for potential answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = 'what ports and connectors does my surface have?' # 'What are potential regulatory actions that can result from an inspection?'\n",
    "# text = pdf_df['text'].to_string(index=True)\n",
    "# text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splits text after sentences ending in a period. Combines n sentences per chunk.\n",
    "# def splitter(n, s):\n",
    "#     pieces = s.split(\". \")\n",
    "#     list_out = [\" \".join(pieces[i:i+n]) for i in range(0, len(pieces), n)]\n",
    "#     return list_out\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
